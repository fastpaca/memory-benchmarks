name: membench-rice
description: Membench benchmark comparing RICE vs long-context baseline
version: "1.0.0"

config:
  concurrency: 5
  timeout_seconds: 600
  proxy:
    enabled: true
    provider: "openai"

agents:
  - name: "long-context-baseline"
    command: "uv run python agents/long_context_agent.py"
    env:
      OPENAI_API_KEY: "${OPENAI_API_KEY}"

  - name: "rice"
    command: "uv run python agents/rice_agent.py"
    env:
      OPENAI_API_KEY: "${OPENAI_API_KEY}"
      DOTENV_PATH: ".env"

datasets:
  - name: "membench"
    source: "git:https://github.com/import-myself/Membench.git"
    prepare: "python scripts/prepare_membench.py"
    input_map:
      input: "question"
      expected: "ground_truth"
    evaluator:
      type: "multiple_choice"
      extra_config:
        fallback: "f1"

output:
  directory: "./runs"
